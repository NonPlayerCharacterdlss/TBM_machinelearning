{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-03-22T12:47:35.679583Z",
     "start_time": "2025-03-22T12:47:35.664753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.matlib import empty\n",
    "from pandas.core.interchange.dataframe_protocol import DataFrame\n",
    "import os\n",
    "import os.path\n",
    "import shutil\n",
    "\n",
    "\n",
    "plt.rcParams['font.sans-serif']=['Songti SC'] #用来正常显示中文标签\n",
    "\n",
    "def read_tbm_data(file_path):\n",
    "    '''\n",
    "    读取TBM数据文件\n",
    "    参数:\n",
    "        file_path: 文件路径\n",
    "    返回:\n",
    "        df: 处理后的DataFrame\n",
    "    '''\n",
    "    #读取第一行，防止列名数和列数不匹配\n",
    "    # 读取数据，使用制表符分隔\n",
    "    df = pd.read_csv(file_path, sep='\\t',index_col=False)\n",
    "    df = df.loc[:,['时间戳','运行时间','刀盘转速','推进速度','刀盘扭矩','贯入度','总推进力','推进速度给定百分比','刀盘给定转速显示值','推进速度电位器设定值']]\n",
    "    return df\n",
    "\n",
    "def tbm_cycle_judge(df,buffer_size = 300,threshold = 0.1):\n",
    "    #可以添加条件(df['总推进力']>0)\n",
    "    df['is_extract'] = (df[\"刀盘转速\"]>0) & (df[\"刀盘扭矩\"]>0) & (df[\"贯入度\"]<=20) &(df[\"贯入度\"]>0)\n",
    "    df['运行时间'] = pd.to_datetime(df['运行时间'])\n",
    "    df.sort_values('运行时间',inplace = True)\n",
    "\n",
    "    #缓冲区buffer_size = 300\n",
    "    #设定阈值用以判断一个小窗口是否符合，比例大于90%则认为是稳定掘进状态,threshold = 0.1\n",
    "    #利用滑动窗口来判断掘进循环\n",
    "    df[\"smoothing\"] = False\n",
    "    #df.rolling()在整个dataframe上使用rolling函数，再调用is_extract列来取窗口平均值判定\n",
    "    extract_mean = df.rolling(window=60, on='运行时间', closed='both')['is_extract'].mean()\n",
    "    df['smoothing'] = extract_mean > threshold\n",
    "\n",
    "\n",
    "    #找到smoothing由false转换为true的那部分（起始索引）,并利用缓冲区往前延伸\n",
    "    smoothing_shift = df['smoothing'].shift(1,fill_value=False)\n",
    "    smoothing_starts = df[(df['smoothing'] == False) & (smoothing_shift == True)].index\n",
    "    for start_idx in smoothing_starts:\n",
    "        buffer_start = max(start_idx-buffer_size, 0)\n",
    "        df.loc[buffer_start:start_idx,'smoothing'] = True\n",
    "\n",
    "    #检测状态变化\n",
    "    df['cycle_id'] = (df['smoothing']!=df['smoothing'].shift(1)).cumsum()\n",
    "    #仅保留掘进状态的循环，df[df['smoothing']]只选择值为true的循环\n",
    "    excavation_cycles = df[df['smoothing']].groupby('cycle_id')\n",
    "    #过滤掉时长不足600s的循环\n",
    "    valid_cycle = []\n",
    "    duration = 0\n",
    "    for cycle_id , cycle in excavation_cycles:\n",
    "        duration = len(cycle)\n",
    "        if duration > 600:\n",
    "            valid_cycle.append({\"cycle_id\": cycle_id,\n",
    "                               'starttime': cycle['运行时间'].iloc[0],\n",
    "                               'endtime' :cycle['运行时间'].iloc[-1],\n",
    "                               'duration': duration,\n",
    "            })\n",
    "    return valid_cycle\n",
    "\n",
    "\n",
    "def display(valid_cycle,tbm_para,df):\n",
    "    cycle_df = pd.DataFrame(valid_cycle)\n",
    "    for index ,cycle in cycle_df.iterrows():\n",
    "        #找出每个循环段的开始和截止时间，以及持续时间\n",
    "        cycle_id = cycle['cycle_id']\n",
    "        start = cycle['starttime']\n",
    "        end = cycle['endtime']\n",
    "        duration = cycle['duration']\n",
    "        #提取，并且利用这个把需要的数据筛选出来\n",
    "        #cycle_data = df[(df['运行时间']>=end - pd.Timedelta(minutes=35)) & (df['运行时间'] <= end)]\n",
    "        #cycle_data = df[(df['运行时间']>=start-pd.Timedelta(minutes=1)) & (df['运行时间'] <= end)]\n",
    "        cycle_data = df[(df['运行时间']>=start) & (df['运行时间'] <= end)]\n",
    "        #绘制图像\n",
    "        plt.figure(dpi = 200)\n",
    "        plt.plot(cycle_data['运行时间'],cycle_data[tbm_para],'b',label = f'Cycle{cycle_id}')\n",
    "        plt.xlabel('运行时间')\n",
    "        plt.ylabel(tbm_para)\n",
    "        plt.title('{}-掘进时间关系图'.format(tbm_para))\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.xticks(rotation = 90)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "'''\n",
    "异常值判定和处理\n",
    "对于掘进过程中的极大异常点,采用 3σ准则判定。\n",
    "通过计算整个掘进步贯入度和掘进速度的均值μ和标准差σ,当掘进速度和贯入度大于μ+ 3σ时,则按照异常点处理。\n",
    "对识别出来的异常点,取5个临近数据点的平均值替代。\n",
    "数据平滑处理\n",
    "为了消除掘进参数中的白噪声,本文采用滑动均值滤波来处理。取窗口长度为n,从第一个数据点开始,计算相邻的n个数据点的算术平均值并作为该点滤波之后的新值,\n",
    "均值滤波的窗口长度决定影响该点数值的数据范围,当选择较大的窗口长度时,可得到更加平滑曲线,但是忽视了很多数据的变化细节,如果选择的窗口长度过小,则噪声消除的效果不够理想。本文采用的滤波窗口长度为15s。\n",
    "'''\n",
    "def handle_outlier_data(df,valid_cycle,col_name,outlier_window):\n",
    "    #这里写3sigma处理的算法\n",
    "    cycle_df = pd.DataFrame(valid_cycle)\n",
    "    for index,cycle in cycle_df.iterrows():\n",
    "        cycle_id = cycle['cycle_id']\n",
    "        start = cycle['starttime']\n",
    "        end = cycle['endtime']\n",
    "        cycle_data = df[(df['运行时间']>=start-pd.Timedelta(minutes=1)) & (df['运行时间'] <= end)]\n",
    "        mu = cycle_data[col_name].mean()\n",
    "        sigma = cycle_data[col_name].std()\n",
    "        outlier = df[df[col_name] > (3*sigma + mu)]\n",
    "        for idx in outlier.index:\n",
    "            start_idx =max(idx - outlier_window, 0)\n",
    "            end_idx = min(len(df),idx + outlier_window)\n",
    "            df.at[idx,col_name] = (df.loc[start_idx:idx-1,col_name].mean()+df.loc[idx+1:end_idx,col_name].mean()+mu)/3.0\n",
    "    return df\n",
    "\n",
    "def smooth_data(df,valid_cycle,col_name,smooth_window):\n",
    "    #这里写smooth处理的方法\n",
    "    cycle_df = pd.DataFrame(valid_cycle)\n",
    "    for index,cycle in cycle_df.iterrows():\n",
    "        cycle_id = cycle['cycle_id']\n",
    "        start = cycle['starttime']\n",
    "        end = cycle['endtime']\n",
    "        cycle_data = df[(df['运行时间']>=start-pd.Timedelta(minutes=1)) & (df['运行时间'] <= end)]\n",
    "        temp = cycle_data[col_name].rolling(window=smooth_window,min_periods=1,center=True).mean()\n",
    "        df.loc[cycle_data.index,col_name] = temp\n",
    "    return df\n",
    "\n",
    "def data_presv(df,valid_cycle,col_names = ['推进速度','贯入度' ,'刀盘扭矩'],outlier_window=20,smooth_window = 15):\n",
    "    #调用上面的两个函数\n",
    "    for col in col_names:\n",
    "        df = handle_outlier_data(df,valid_cycle,col,outlier_window)\n",
    "        df = smooth_data(df,valid_cycle,col,smooth_window)\n",
    "    return df"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T12:47:46.658228Z",
     "start_time": "2025-03-22T12:47:46.648574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classify_excavation_phase(df,cycle_list,T_threshold = 0,Tf_threshold = 600,Ff_threshold = 1000,sigma_threshold = 100,duration_threshold = 1000,v_set_rate = 0.1):\n",
    "    #T_threshold = 0\n",
    "    #Tf_threshold = 600\n",
    "    #Ff_threshold = 1000\n",
    "    #duration_threshold = 60\n",
    "    phase_list = []\n",
    "    cycle_list = pd.DataFrame(cycle_list)\n",
    "    for index,cycle in cycle_list.iterrows():\n",
    "        cycle_id = cycle['cycle_id']\n",
    "        start = cycle['starttime']\n",
    "        end = cycle['endtime']\n",
    "        cycle_data = df[(df['运行时间']>=start-pd.Timedelta(minutes=1)) & (df['运行时间'] <= end)].copy()\n",
    "\n",
    "        #空推段\n",
    "        push_start = cycle_data[cycle_data['刀盘扭矩']>T_threshold].index\n",
    "        push_start_time = cycle_data.at[push_start[0],'运行时间'] if not push_start.empty else None\n",
    "\n",
    "        #上升段\n",
    "        rising_start = cycle_data[(cycle_data['刀盘扭矩'] > Tf_threshold) & (cycle_data['总推进力'] > Ff_threshold)].index\n",
    "        rising_start_time = cycle_data.at[rising_start[0],'运行时间'] if not rising_start.empty else None\n",
    "\n",
    "        #稳定段\n",
    "        #stable_phase_data = cycle_data[cycle_data['运行时间'] > rising_start_time].copy()\n",
    "        cycle_data['v_std'] = cycle_data['推进速度'].rolling(window = 60,min_periods=1).std()\n",
    "        cycle_data['v_set_std'] = cycle_data['推进速度电位器设定值'].rolling(window = 30,min_periods=1).std()\n",
    "        cycle_data['v_set_m'] = cycle_data['推进速度电位器设定值'].rolling(window = 60,min_periods=1).mean()\n",
    "\n",
    "        #动态阈值设定，防止返回none\n",
    "        #sigma_threshold = cycle_data['v_set_std'].mean()*sigma_threshold\n",
    "        v_set_threshold = cycle_data['v_set_m']*v_set_rate\n",
    "\n",
    "        #条件为设定10%的阈值+利用设定推进速度的sigma来判断\n",
    "        conditions = (cycle_data['v_set_std']<=sigma_threshold)&(cycle_data['推进速度电位器设定值']>cycle_data['v_set_std']*10)\n",
    "        #conditions = (cycle_data['v_set_std']<=sigma_threshold)(cycle_data['推进速度']>v_set_threshold)\n",
    "\n",
    "        cycle_data['is_stable_candidate'] = conditions\n",
    "        #检查是否有duration_threshold的持续稳定，文中设定为60s\n",
    "        stable_candidates = cycle_data[(cycle_data['is_stable_candidate']) & (cycle_data['运行时间']>rising_start_time+pd.Timedelta(minutes=1))].copy()\n",
    "        #stable_candidates = cycle_data[cycle_data['v_set_std'] <= sigma_threshold].copy()\n",
    "        stable_candidates['diff'] = stable_candidates['运行时间'].diff().dt.total_seconds()\n",
    "        stable_candidates['group'] = (stable_candidates['diff'] > 3).cumsum()\n",
    "        stable_groups = stable_candidates.groupby('group')\n",
    "\n",
    "        stable_start_time = rising_start_time\n",
    "        for group_id, group in stable_groups:\n",
    "            duration = (group['运行时间'].iloc[-1] - group['运行时间'].iloc[0]).total_seconds()\n",
    "            if duration >= duration_threshold:\n",
    "                stable_start_time = group['运行时间'].iloc[0]\n",
    "                break\n",
    "        #下降段\n",
    "        falling_start = cycle_data[(cycle_data['运行时间'] > stable_start_time)&(cycle_data['刀盘扭矩'] <= Tf_threshold) &(cycle_data['总推进力'] <= Ff_threshold)].index\n",
    "\n",
    "        #falling_start = cycle_data[(cycle_data['刀盘扭矩'] <= Tf_threshold) &(cycle_data['总推进力'] <= Ff_threshold)].index\n",
    "        falling_start_time = cycle_data.at[falling_start[0], '运行时间'] if not falling_start.empty else None\n",
    "\n",
    "        phases = {\n",
    "                'cycle_id': cycle_id,\n",
    "                'push_start': push_start_time,\n",
    "                'rising_start': rising_start_time,\n",
    "                'stable_start': stable_start_time,\n",
    "                'falling_start': falling_start_time\n",
    "            }\n",
    "        phase_list.append(phases)\n",
    "\n",
    "\n",
    "    return phase_list\n"
   ],
   "id": "28bffdfe5674092a",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T12:47:56.341572Z",
     "start_time": "2025-03-22T12:47:56.333590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_cycle_phases(df, phase_list, tbm_param='刀盘扭矩', buffer_minutes=0):\n",
    "    '''\n",
    "    绘制每个有效循环的图像，并标记各阶段起点\n",
    "    参数:\n",
    "        df: DataFrame，包含原始数据。\n",
    "        phase_list: 阶段划分后的列表，每个元素包含 cycle_id 和各阶段的起点时间。\n",
    "        tbm_param: 要绘制的参数列名（如'刀盘扭矩'、'推进速度'）。\n",
    "        buffer_minutes: 缓冲区时间（分钟）。\n",
    "    '''\n",
    "    for phase in phase_list:\n",
    "        cycle_id = phase['cycle_id']\n",
    "        push_start = phase['push_start']\n",
    "        rising_start = phase['rising_start']\n",
    "        stable_start = phase['stable_start']\n",
    "        falling_start = phase['falling_start']\n",
    "\n",
    "        # 定义循环的开始和结束时间，包含缓冲区前1分钟\n",
    "        # 假设 cycle['starttime'] 和 cycle['endtime'] 存在\n",
    "        # 但在 phase_list 中只有 'push_start', 'rising_start' 等\n",
    "        # 所以需要根据具体情况调整\n",
    "        # 这里假设 'push_start' 是循环的开始\n",
    "        start_time = push_start - pd.Timedelta(minutes=buffer_minutes) if push_start else None\n",
    "        # 结束时间可以根据数据范围或其他逻辑确定\n",
    "        # 这里假设循环结束时间为 'falling_start' 后的某个时间点\n",
    "        end_time = falling_start + pd.Timedelta(minutes=buffer_minutes) if falling_start else None\n",
    "\n",
    "        # 提取循环数据\n",
    "        if start_time and end_time:\n",
    "            cycle_data = df[(df['运行时间'] >= start_time) & (df['运行时间'] <= end_time)].copy()\n",
    "        elif start_time:\n",
    "            cycle_data = df[df['运行时间'] >= start_time].copy()\n",
    "        elif end_time:\n",
    "            cycle_data = df[df['运行时间'] <= end_time].copy()\n",
    "        else:\n",
    "            cycle_data = df.copy()\n",
    "\n",
    "        # 检查是否有数据\n",
    "        if cycle_data.empty:\n",
    "            print(f\"Cycle {cycle_id} has no data in the specified time range.\")\n",
    "            continue\n",
    "\n",
    "        # 绘制参数曲线\n",
    "        plt.figure(figsize=(12, 6),dpi=200)\n",
    "        plt.plot(cycle_data['运行时间'], cycle_data[tbm_param], label=f'Cycle {cycle_id} {tbm_param}')\n",
    "\n",
    "        # 标记各阶段起点\n",
    "        if push_start:\n",
    "            plt.axvline(push_start, color='green', linestyle='--', label='空推段起点')\n",
    "        if rising_start:\n",
    "            plt.axvline(rising_start, color='orange', linestyle='--', label='上升段起点')\n",
    "        if stable_start:\n",
    "            plt.axvline(stable_start, color='blue', linestyle='--', label='稳定段起点')\n",
    "        if falling_start:\n",
    "            plt.axvline(falling_start, color='red', linestyle='--', label='下降段起点')\n",
    "\n",
    "        plt.xlabel('运行时间')\n",
    "        plt.ylabel(tbm_param)\n",
    "        plt.title(f'{tbm_param} - 掘进时间关系图 (Cycle {cycle_id})')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "id": "bb45fbd15f33e9d6",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T12:47:56.984189Z",
     "start_time": "2025-03-22T12:47:56.981568Z"
    }
   },
   "cell_type": "code",
   "source": "import shutil",
   "id": "a3e999e073b76aa6",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T12:47:58.453579Z",
     "start_time": "2025-03-22T12:47:58.450072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def unzip_file(zip_path = '/Users/xudongzuo/Library/CloudStorage/OneDrive-个人/文档/workspace/test_data' ,unzip_path = '/Users/xudongzuo/Library/CloudStorage/OneDrive-个人/文档/workspace/test_data/un_zip',type = '.zip'):\n",
    "    #确保输出文件夹存在\n",
    "    chdir = os.chdir(zip_path)\n",
    "    if not os.path.exists(unzip_path):\n",
    "        try:\n",
    "            os.mkdir(unzip_path)\n",
    "        except Exception as e:\n",
    "            print(f'无法创建目标文件夹{unzip_path}')\n",
    "    for file in os.listdir(zip_path):\n",
    "        if file.endswith(type):\n",
    "            shutil.unpack_archive(file,unzip_path)"
   ],
   "id": "c03d8a80b6fe14a5",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T12:48:00.979904Z",
     "start_time": "2025-03-22T12:48:00.875215Z"
    }
   },
   "cell_type": "code",
   "source": "unzip_file()",
   "id": "353e133f5fb52a46",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T12:48:01.446307Z",
     "start_time": "2025-03-22T12:48:01.444179Z"
    }
   },
   "cell_type": "code",
   "source": "print(os.listdir('/Users/xudongzuo/Library/CloudStorage/OneDrive-个人/文档/workspace/test_data/un_zip'))",
   "id": "5b7b40d41c80d194",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CREC188_20150713.txt', 'CREC188_20150707.txt', 'CREC188_20150712.txt', 'CREC188_20150710.txt', 'CREC188_20170629.txt', 'CREC188_20150711.txt', 'CREC188_20150708.txt', 'CREC188_20150709.txt']\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T12:48:02.216396Z",
     "start_time": "2025-03-22T12:48:02.213122Z"
    }
   },
   "cell_type": "code",
   "source": "list_of_bc = os.listdir('/Users/xudongzuo/Library/CloudStorage/OneDrive-个人/文档/workspace/test_data/un_zip')",
   "id": "738322ac72eac2dc",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T12:48:03.545979Z",
     "start_time": "2025-03-22T12:48:03.542516Z"
    }
   },
   "cell_type": "code",
   "source": "list_of_bc",
   "id": "1df86de3e3a168a2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CREC188_20150713.txt',\n",
       " 'CREC188_20150707.txt',\n",
       " 'CREC188_20150712.txt',\n",
       " 'CREC188_20150710.txt',\n",
       " 'CREC188_20170629.txt',\n",
       " 'CREC188_20150711.txt',\n",
       " 'CREC188_20150708.txt',\n",
       " 'CREC188_20150709.txt']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T12:48:04.937118Z",
     "start_time": "2025-03-22T12:48:04.930139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def save_process(df, phase_list, output_folder, start_cycle_id=1):\n",
    "    '''\n",
    "    读取TBM数据文件，并对每个循环重新标注 cycle_id（保证全局连续）\n",
    "    参数:\n",
    "        df：包含了提取循环后的所有数据\n",
    "        phase_list：记录掘进分段节点时间的列表，\n",
    "                    例如：[{'cycle_id': 2, 'push_start': Timestamp(...),\n",
    "                             'rising_start': Timestamp(...),\n",
    "                             'stable_start': Timestamp(...),\n",
    "                             'falling_start': Timestamp(...)}]\n",
    "        output_folder: 文件输出路径\n",
    "        start_cycle_id: 本次处理的起始 cycle_id\n",
    "    返回:\n",
    "        combined_df: 处理后的DataFrame\n",
    "        next_cycle_id: 下一个可用的 cycle_id（即全局连续计数器的最新值）\n",
    "    '''\n",
    "    all_cycle_data = []\n",
    "    current_cycle_id = start_cycle_id  # 使用传入的初始值\n",
    "\n",
    "    for phase in phase_list:\n",
    "        # 使用全局的 current_cycle_id 而非 phase['cycle_id']\n",
    "        cycle_id = current_cycle_id\n",
    "        current_cycle_id += 1\n",
    "\n",
    "        rising_start = phase['rising_start']\n",
    "        stable_start = phase['stable_start']\n",
    "        falling_start = phase['falling_start']\n",
    "\n",
    "        # 标记空推段，只需要用上升段预测稳定段\n",
    "        rising_data = df[(df['运行时间'] > rising_start) & (df['运行时间'] < stable_start)].copy()\n",
    "        stable_data = df[(df['运行时间'] > stable_start) & (df['运行时间'] < falling_start)].copy()\n",
    "\n",
    "        rising_data['cycle_id'] = cycle_id\n",
    "        stable_data['cycle_id'] = cycle_id\n",
    "        rising_data['phase_label'] = 'rising'\n",
    "        stable_data['phase_label'] = 'stable'\n",
    "\n",
    "        all_cycle_data.append(rising_data)\n",
    "        all_cycle_data.append(stable_data)\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    basename = 'data'\n",
    "    output_path = os.path.join(output_folder, f'{basename}_process.csv')\n",
    "\n",
    "    if all_cycle_data:\n",
    "        combined_df = pd.concat(all_cycle_data, ignore_index=True)\n",
    "        # 判断输出文件是否存在，存在则追加，否则写入表头\n",
    "        if not os.path.exists(output_path):\n",
    "            combined_df.to_csv(path_or_buf=output_path, index=False, mode='w', header=True)\n",
    "        else:\n",
    "            combined_df.to_csv(path_or_buf=output_path, index=False, mode='a', header=False)\n",
    "        return combined_df, current_cycle_id\n",
    "    else:\n",
    "        return None, start_cycle_id"
   ],
   "id": "510abf6be486c56a",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def save_process4test(df,phase_list,output_folder):\n",
    "    '''\n",
    "    读取TBM数据文件\n",
    "    参数:\n",
    "        output_folder: 文件输出路径\n",
    "    返回:\n",
    "        df: 处理后的DataFrame\n",
    "    '''\n",
    "    all_cycle_data = []\n",
    "    for phase in phase_list:\n",
    "        push_start = phase['push_start']\n",
    "        rising_start = phase['rising_start']\n",
    "        stable_start = phase['stable_start']\n",
    "        falling_start = phase['falling_start']\n",
    "\n",
    "        buffer_minutes = 0\n",
    "        start_time = push_start - pd.Timedelta(minutes=buffer_minutes) if push_start else None\n",
    "        # 结束时间可以根据数据范围或其他逻辑确定\n",
    "        # 这里假设循环结束时间为 'falling_start' 后的某个时间点\n",
    "        end_time = falling_start + pd.Timedelta(minutes=buffer_minutes) if falling_start else None\n",
    "\n",
    "        #标记空推段，只需要用上升段预测稳定段\n",
    "        push_data = df[(df['运行时间']>start_time)&(df['运行时间']<end_time)]\n",
    "\n",
    "        all_cycle_data.append(push_data)\n",
    "    os.makedirs(output_folder,exist_ok = True)\n",
    "    basename = 'data'\n",
    "    output_path = os.path.join(output_folder,f'{basename}_process.csv')\n",
    "    if all_cycle_data:\n",
    "        combined_df = pd.concat(all_cycle_data,ignore_index=True)\n",
    "        #确保有输出文件夹\n",
    "        if not os.path.exists(output_folder):\n",
    "            combined_df.to_csv(path_or_buf=output_path,index = False,mode='w')\n",
    "        else:\n",
    "            #文件已经存在跳过header\n",
    "            combined_df.to_csv(path_or_buf=output_path,index = False,mode='a')"
   ],
   "id": "65ec58126ed5af52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T12:48:30.857218Z",
     "start_time": "2025-03-22T12:48:08.350292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = []\n",
    "global_cycle_id = 1 #设置全局cycle_id值\n",
    "input_folder = '/Users/xudongzuo/Library/CloudStorage/OneDrive-个人/文档/workspace/test_data/un_zip'\n",
    "output_folder = '/Users/xudongzuo/Library/CloudStorage/OneDrive-个人/文档/workspace/test_data/processed'\n",
    "for file in list_of_bc:\n",
    "    df = read_tbm_data('/Users/xudongzuo/Library/CloudStorage/OneDrive-个人/文档/workspace/test_data/un_zip/'+file)\n",
    "    #取出这天的循环列表，方便我后面用手段对数据进行划分\n",
    "    cycle_list = tbm_cycle_judge(df)\n",
    "    df = data_presv(df,cycle_list,col_names=['推进速度','贯入度','刀盘扭矩','刀盘转速','刀盘给定转速显示值','推进速度给定百分比'],outlier_window = 5,smooth_window = 5)\n",
    "    phase_list = classify_excavation_phase(df,cycle_list,T_threshold = 0,Tf_threshold = 600,Ff_threshold = 1000,sigma_threshold = 20,duration_threshold = 60,v_set_rate = 0)\n",
    "    processed_df,global_cycle_id = save_process(df,phase_list,output_folder,start_cycle_id=global_cycle_id)\n",
    "    data += phase_list\n",
    "\n",
    "    #plt.figure(figsize=(12, 6),dpi=200)\n",
    "    #plt.plot(df['运行时间'], df['刀盘转速'])"
   ],
   "id": "3b3a48be8e7c205d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2b/lrgpb6l56qq7z0p0v5dqkb7h0000gn/T/ipykernel_1344/2784659841.py:24: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_csv(file_path, sep='\\t',index_col=False)\n",
      "/var/folders/2b/lrgpb6l56qq7z0p0v5dqkb7h0000gn/T/ipykernel_1344/2784659841.py:24: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_csv(file_path, sep='\\t',index_col=False)\n",
      "/var/folders/2b/lrgpb6l56qq7z0p0v5dqkb7h0000gn/T/ipykernel_1344/2784659841.py:24: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_csv(file_path, sep='\\t',index_col=False)\n",
      "/var/folders/2b/lrgpb6l56qq7z0p0v5dqkb7h0000gn/T/ipykernel_1344/2784659841.py:24: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_csv(file_path, sep='\\t',index_col=False)\n",
      "/var/folders/2b/lrgpb6l56qq7z0p0v5dqkb7h0000gn/T/ipykernel_1344/2784659841.py:24: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_csv(file_path, sep='\\t',index_col=False)\n",
      "/var/folders/2b/lrgpb6l56qq7z0p0v5dqkb7h0000gn/T/ipykernel_1344/2784659841.py:24: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_csv(file_path, sep='\\t',index_col=False)\n",
      "/var/folders/2b/lrgpb6l56qq7z0p0v5dqkb7h0000gn/T/ipykernel_1344/2784659841.py:24: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_csv(file_path, sep='\\t',index_col=False)\n",
      "/var/folders/2b/lrgpb6l56qq7z0p0v5dqkb7h0000gn/T/ipykernel_1344/2784659841.py:24: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_csv(file_path, sep='\\t',index_col=False)\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = []\n",
    "input_folder = '/Users/xudongzuo/Library/CloudStorage/OneDrive-个人/文档/workspace/test_data/un_zip'\n",
    "output_folder = '/Users/xudongzuo/Library/CloudStorage/OneDrive-个人/文档/workspace/test_data/processed'\n",
    "for file in list_of_bc:\n",
    "    df = read_tbm_data('/Users/xudongzuo/Library/CloudStorage/OneDrive-个人/文档/workspace/test_data/un_zip/'+file)\n",
    "    #取出这天的循环列表，方便我后面用手段对数据进行划分\n",
    "    cycle_list = tbm_cycle_judge(df)\n",
    "    df = data_presv(df,cycle_list,col_names=['推进速度','贯入度','刀盘扭矩','刀盘转速','刀盘给定转速显示值',''],outlier_window = 5,smooth_window = 5)\n",
    "    #save_process(df,file,output_folder,)\n",
    "    phase_list = classify_excavation_phase(df,cycle_list,T_threshold = 0,Tf_threshold = 600,Ff_threshold = 1000,sigma_threshold = 20,duration_threshold = 180,v_set_rate = 0)\n",
    "    save_process4test(df,phase_list,output_folder)\n",
    "    data += phase_list\n",
    "    #批量画图用以修改阈值\n",
    "    plot_cycle_phases(df, phase_list, tbm_param='刀盘扭矩', buffer_minutes=0)\n",
    "    plt.figure(figsize=(12, 6),dpi=200)\n",
    "    #plt.plot(df['运行时间'], df['刀盘转速'])"
   ],
   "id": "4d3e5b674d0e165e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T07:16:34.148096Z",
     "start_time": "2025-03-22T07:16:33.918780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fp = '/Users/xudongzuo/Library/CloudStorage/OneDrive-个人/文档/workspace/test_data/processed/data_process'\n",
    "df = pd.read_csv(fp, sep=',',index_col=False)"
   ],
   "id": "b3c45e7e7891f103",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/xudongzuo/Library/CloudStorage/OneDrive-个人/文档/workspace/test_data/processed/data_process'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m fp \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/Users/xudongzuo/Library/CloudStorage/OneDrive-个人/文档/workspace/test_data/processed/data_process\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 2\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m,\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mindex_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1879\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1887\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1889\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1890\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1891\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/pandas/io/common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    869\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    872\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/Users/xudongzuo/Library/CloudStorage/OneDrive-个人/文档/workspace/test_data/processed/data_process'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df",
   "id": "2cc5240283c483fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data",
   "id": "70464ad90cc8f760",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 假设我们使用上升段的时间序列数据作为输入\n",
    "# 定义序列长度（时间步数）\n",
    "time_steps = 60  # 例如，60秒的序列\n",
    "\n",
    "# 提取上升段序列数据\n",
    "# 假设上升段的时间范围内有足够的数据点\n",
    "input_features = ['刀盘转速', '推进速度', '总推进力', '刀盘扭矩', '贯入度']\n",
    "output_features = ['avg_stable_torque', 'avg_stable_thrust']\n",
    "\n",
    "# 创建输入和输出列表\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for phase in data:\n",
    "    cycle_id = phase['cycle_id']\n",
    "    rising_start = phase['rising_start']\n",
    "    stable_start = phase['stable_start']\n",
    "    falling_start = phase['falling_start']\n",
    "\n",
    "    # 提取上升段数据\n",
    "    rising_data = df[(df['运行时间'] >= rising_start) & (df['运行时间'] < stable_start)]\n",
    "\n",
    "    # 确保有足够的时间步\n",
    "    if len(rising_data) < time_steps:\n",
    "        continue  # 或者使用填充\n",
    "    else:\n",
    "        # 滚动窗口生成序列\n",
    "        for i in range(len(rising_data) - time_steps + 1):\n",
    "            seq = rising_data.iloc[i:i+time_steps][input_features].values\n",
    "            X.append(seq)\n",
    "\n",
    "            # 对应的稳定段参数\n",
    "            stable_data = df[(df['运行时间'] >= stable_start) & (df['运行时间'] < falling_start)]\n",
    "            if not stable_data.empty:\n",
    "                avg_stable_torque = stable_data['刀盘扭矩'].mean()\n",
    "                avg_stable_thrust = stable_data['总推进力'].mean()\n",
    "                y.append([avg_stable_torque, avg_stable_thrust])\n",
    "            else:\n",
    "                y.append([np.nan, np.nan])  # 处理缺失值\n",
    "\n",
    "# 转换为numpy数组\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 移除包含NaN的样本\n",
    "valid_indices = ~np.isnan(y).any(axis=1)\n",
    "X = X[valid_indices]\n",
    "y = y[valid_indices]\n",
    "\n",
    "print(f'Input shape: {X.shape}')\n",
    "print(f'Output shape: {y.shape}')"
   ],
   "id": "ac87c3476071d35d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import csv\n",
    "\n",
    "# Define LSTM Neural Networks\n",
    "class LstmRNN(nn.Module):\n",
    "    \"\"\"\n",
    "        Parameters：\n",
    "        - input_size: feature size\n",
    "        - hidden_size: number of hidden units\n",
    "        - output_size: number of output\n",
    "        - num_layers: layers of LSTM to stack\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size=1, output_size=1, num_layers=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)  # utilize the LSTM model in torch.nn\n",
    "        self.linear1 = nn.Linear(hidden_size, output_size) # 全连接层\n",
    "\n",
    "    def forward(self, _x):\n",
    "        x, _ = self.lstm(_x)  # _x is input, size (seq_len, batch, input_size)\n",
    "        s, b, h = x.shape  # x is output, size (seq_len, batch, hidden_size)\n",
    "        x = self.linear1(x)\n",
    "        return x[-1, :, :]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # checking if GPU is available\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    if (torch.cuda.is_available()):\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print('Training on GPU.')\n",
    "    else:\n",
    "        print('No GPU available, training on CPU.')\n",
    "\n",
    "    # 数据读取&类型转换\n",
    "    data_x = np.array(pd.read_csv('Data_x.csv', header=None)).astype('float32')\n",
    "    data_y = np.array(pd.read_csv('Data_y.csv', header=None)).astype('float32')\n",
    "\n",
    "    # 数据集分割\n",
    "    data_len = len(data_x)\n",
    "    t = np.linspace(0, data_len, data_len + 1)\n",
    "\n",
    "    train_data_ratio = 0.8  # Choose 80% of the data for training\n",
    "    train_data_len = int(data_len * train_data_ratio)\n",
    "\n",
    "    train_x = data_x[5:train_data_len]\n",
    "    train_y = data_y[5:train_data_len]\n",
    "    t_for_training = t[5:train_data_len]\n",
    "\n",
    "    test_x = data_x[train_data_len:]\n",
    "    test_y = data_y[train_data_len:]\n",
    "    t_for_testing = t[train_data_len:]\n",
    "\n",
    "    # ----------------- train -------------------\n",
    "    INPUT_FEATURES_NUM = 1\n",
    "    OUTPUT_FEATURES_NUM = 1\n",
    "    train_x_tensor = train_x.reshape(5, -1, INPUT_FEATURES_NUM)\n",
    "    train_y_tensor = train_y.reshape(1, OUTPUT_FEATURES_NUM)\n",
    "    # transfer data to pytorch tensor\n",
    "    train_x_tensor = torch.from_numpy(train_x_tensor)\n",
    "    train_y_tensor = torch.from_numpy(train_y_tensor)\n",
    "\n",
    "    lstm_model = LstmRNN(INPUT_FEATURES_NUM, 20, output_size=OUTPUT_FEATURES_NUM, num_layers=1)  # 20 hidden units\n",
    "    print('LSTM model:', lstm_model)\n",
    "    print('model.parameters:', lstm_model.parameters)\n",
    "    print('train x tensor dimension:', Variable(train_x_tensor).size())\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(lstm_model.parameters(), lr=1e-2)\n",
    "\n",
    "    prev_loss = 1000\n",
    "    max_epochs = 2000\n",
    "\n",
    "    train_x_tensor = train_x_tensor.to(device)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        output = lstm_model(train_x_tensor).to(device)\n",
    "        loss = criterion(output, train_y_tensor)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if loss < prev_loss:\n",
    "            torch.save(lstm_model.state_dict(), 'lstm_model.pt')  # save model parameters to files\n",
    "            prev_loss = loss\n",
    "\n",
    "        if loss.item() < 1e-4:\n",
    "            print('Epoch [{}/{}], Loss: {:.5f}'.format(epoch + 1, max_epochs, loss.item()))\n",
    "            print(\"The loss value is reached\")\n",
    "            break\n",
    "        elif (epoch + 1) % 100 == 0:\n",
    "            print('Epoch: [{}/{}], Loss:{:.5f}'.format(epoch + 1, max_epochs, loss.item()))\n",
    "\n",
    "    # prediction on training dataset\n",
    "    pred_y_for_train = lstm_model(train_x_tensor).to(device)\n",
    "    pred_y_for_train = pred_y_for_train.view(-1, OUTPUT_FEATURES_NUM).data.numpy()\n",
    "\n",
    "    # ----------------- test -------------------\n",
    "    lstm_model = lstm_model.eval()  # switch to testing model\n",
    "\n",
    "    # prediction on test dataset\n",
    "    test_x_tensor = test_x.reshape(5, -1, INPUT_FEATURES_NUM)\n",
    "    test_x_tensor = torch.from_numpy(test_x_tensor)  # 变为tensor\n",
    "    test_x_tensor = test_x_tensor.to(device)\n",
    "\n",
    "    pred_y_for_test = lstm_model(test_x_tensor).to(device)\n",
    "    pred_y_for_test = pred_y_for_test.view(-1, OUTPUT_FEATURES_NUM).data.numpy()\n",
    "\n",
    "    loss = criterion(torch.from_numpy(pred_y_for_test), torch.from_numpy(test_y))\n",
    "    print(\"test loss：\", loss.item())\n",
    "\n",
    "    # ----------------- plot -------------------\n",
    "    plt.figure()\n",
    "    plt.plot(t_for_training, train_y, 'b', label='y_trn')\n",
    "    plt.plot(t_for_training, pred_y_for_train, 'y--', label='pre_trn')\n",
    "\n",
    "    plt.plot(t_for_testing, test_y, 'k', label='y_tst')\n",
    "    plt.plot(t_for_testing, pred_y_for_test, 'm--', label='pre_tst')\n",
    "\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('Vce')\n",
    "    plt.show()"
   ],
   "id": "3fa9fd36d4d286b1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
